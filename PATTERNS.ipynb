{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PATTERNS",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dabarreiroh/Patterndsesign/blob/master/PATTERNS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15Zt_0sJiA0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e85cbe-73cb-4eb0-edc5-843c0cdc35e3"
      },
      "source": [
        "# Seleccionamos la versión más reciente de tensorflow 2.\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "    %load_ext tensorboard\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")\n",
        "# Seleccionamos una semilla para los RNG\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5si8UkD2lS5J"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWzUcAaGMv7n"
      },
      "source": [
        "tickets = pd.read_csv('datasetpatterns.csv', sep=',',low_memory=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrPqgg9Wh03Q"
      },
      "source": [
        "clients=pd.read_csv('clients.csv', sep=',',low_memory=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZl5JlP-uOra"
      },
      "source": [
        "tickets['listregistrant']=tickets.listregistrant.map(lambda x: \"REGISTRANTDTP:\"+str(x).replace(\" \",\"\"))\n",
        "tickets['listregistrar']=tickets.listregistrar.map(lambda x: \"REGISTRARTDTP:\"+str(x).replace(\" \",\"\"))\n",
        "tickets['listhosting']=tickets.listhosting.map(lambda x: \"HOSTINGDTP:\"+str(x).replace(\" \",\"\"))\n",
        "tickets['listcountry']=tickets.listcountry.map(lambda x: \"PAISDTP:\"+str(x).replace(\" \",\"\"))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1nqiAlJiBLL"
      },
      "source": [
        "clients=clients[[\"'cli_id_client'\",\"'cli_public_id'\"]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yOrRjNCiUzd"
      },
      "source": [
        "tickets=tickets.set_index(\"'tic_id_client'\").join(clients.set_index(\"'cli_id_client'\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky72CGKkBpBX"
      },
      "source": [
        "tickets=tickets[tickets[\"'tic_ip'\"].notna() & tickets['listcountry'].notna() & tickets['listhosting'].notna() &  tickets['listregistrar'].notna() & tickets[\"'cli_public_id'\"].notna()&tickets['listregistrant'].notna()]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezN52vkAzPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cd4711-8d4d-4b7b-9e69-8c13fc7c36d0"
      },
      "source": [
        "tickets.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', ''tic_country_attack'', ''tic_domain'', ''tic_ip'',\n",
              "       ''tic_url'', 'listregistrant', 'listregistrar', 'listhosting',\n",
              "       'listcountry', ''cli_public_id''],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ5IgIoVPDlg"
      },
      "source": [
        "tickets=tickets[[\"'tic_country_attack'\",\"'tic_domain'\",\"'tic_ip'\",\"'tic_url'\",'listregistrant', 'listregistrar',\n",
        "       'listhosting', 'listcountry',\"'cli_public_id'\"]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivd_QMfgPuEr"
      },
      "source": [
        "tickets['simpleurl']=tickets[\"'tic_url'\"].map(lambda x: '/'.join([str(elem) for elem in x.split('//')[-1].split('/')[1:]]) if (x.split('//')[-1].split('/')[1:]!=(['']))and(x.split('//')[-1].split('/')[1:]!=([])) else np.nan)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxFiVEd8jXcm"
      },
      "source": [
        "tickets['simpleurl']=tickets['simpleurl'].map(lambda x: \"PATHDTP:\"+str(x).replace(\" \",\"\"))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_MxSFCUBzPV"
      },
      "source": [
        "tickets=tickets[tickets.simpleurl.notna()]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BecpBiw0g9GQ"
      },
      "source": [
        "paths=[]\n",
        "for element in tickets.simpleurl.to_list():\n",
        "  try:\n",
        "    paths=paths+element\n",
        "  except:\n",
        "    paths=paths+[\"xyzxyzxyz\"]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVGeNZ9WJnRN"
      },
      "source": [
        "Nuestro vocabulario (a nivel de caracter) está conformado de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih-q2uZ0RYKH"
      },
      "source": [
        "listtype=lambda x: [str(i) for i in x]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHjGSbBwR1PQ"
      },
      "source": [
        "tickets=tickets[tickets.simpleurl.notna()]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h95u72BdW-e4"
      },
      "source": [
        "tickets[\"'cli_public_id'\"]=listtype(tickets[\"'cli_public_id'\"])\n",
        "tickets[\"'tic_ip'\"]=listtype(tickets[\"'tic_ip'\"])\n",
        "tickets['simpleurl']=listtype(tickets['simpleurl'])\n",
        "tickets['listregistrant']=listtype(tickets['listregistrant'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPaxbtc8iIT_"
      },
      "source": [
        "tickets['text']=tickets[[\"'cli_public_id'\",\"'tic_ip'\",'listregistrant','listregistrar','listhosting','listcountry','simpleurl']].apply(lambda x: ' '.join(x), axis=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP443VBB_ry-"
      },
      "source": [
        "text=tickets.text.map(lambda x: x.split(' '))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e6sJg39BHaD"
      },
      "source": [
        "text=text.map(lambda x: [element for element in x if element!=''])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oarCfhyFt7a"
      },
      "source": [
        "texto=text.sum()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJhooSEaY-Ht"
      },
      "source": [
        "client=tickets[\"'cli_public_id'\"].unique()\n",
        "ip=tickets[\"'tic_ip'\"].unique()\n",
        "path=tickets['simpleurl'].unique()\n",
        "registrant=tickets['listregistrant'].unique()\n",
        "registrar=tickets['listregistrar'].unique()\n",
        "hosting=tickets['listhosting'].unique()\n",
        "country=tickets['listcountry'].unique()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDLuRF_xhoNW"
      },
      "source": [
        "vocabA={client[i]:i for i in range(len(client))}\n",
        "vocabB={ip[i]:i+len(vocabA) for i in range(len(ip))}\n",
        "vocabC={path[i]:i+len(vocabA)+len(vocabB) for i in range(len(path))}\n",
        "vocabD={registrant[i]:i+len(vocabA)+len(vocabB)+len(vocabC) for i in range(len(registrant))}\n",
        "vocabE={registrar[i]:i+len(vocabA)+len(vocabB)+len(vocabC)+len(vocabD) for i in range(len(registrar))}\n",
        "vocabF={hosting[i]:i+len(vocabA)+len(vocabB)+len(vocabC)+len(vocabD)+len(vocabE) for i in range(len(hosting))}\n",
        "vocabG={country[i]:i+len(vocabA)+len(vocabB)+len(vocabC)+len(vocabD)+len(vocabE)+len(vocabF) for i in range(len(country))}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oogYZhv-hwAw"
      },
      "source": [
        "reversevocabA={i:client[i] for i in range(len(client))}\n",
        "reversevocabB={i+len(reversevocabA):ip[i] for i in range(len(ip))}\n",
        "reversevocabC={i+len(reversevocabA)+len(reversevocabB):path[i] for i in range(len(path))}\n",
        "reversevocabD={i+len(reversevocabA)+len(reversevocabB)+len(reversevocabC):registrant[i] for i in range(len(registrant))}\n",
        "reversevocabE={i+len(reversevocabA)+len(reversevocabB)+len(reversevocabC)+len(reversevocabD):registrar[i] for i in range(len(registrar))}\n",
        "reversevocabF={i+len(reversevocabA)+len(reversevocabB)+len(reversevocabC)+len(reversevocabD)+len(reversevocabE):hosting[i] for i in range(len(hosting))}\n",
        "reversevocabG={i+len(reversevocabA)+len(reversevocabB)+len(reversevocabC)+len(reversevocabD)+len(reversevocabE)+len(reversevocabF):country[i] for i in range(len(country))}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXD3CYt_d95T"
      },
      "source": [
        "vocab=vocabA\n",
        "vocab.update(vocabB)\n",
        "vocab.update(vocabC)\n",
        "vocab.update(vocabD)\n",
        "vocab.update(vocabE)\n",
        "vocab.update(vocabF)\n",
        "vocab.update(vocabG)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oPmBrhA-GbD"
      },
      "source": [
        "reversevocab=reversevocabA\n",
        "reversevocab.update(reversevocabB)\n",
        "reversevocab.update(reversevocabC)\n",
        "reversevocab.update(reversevocabD)\n",
        "reversevocab.update(reversevocabE)\n",
        "reversevocab.update(reversevocabF)\n",
        "reversevocab.update(reversevocabG)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEOiiUC-JrZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623d9f5c-c269-4d37-d17e-87bf46a84150"
      },
      "source": [
        "# obtenemos los carácteres únicos en el texto\n",
        "vocab_size = len(vocab)\n",
        "print(f'Se encontraron {vocab_size} carácteres únicos')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se encontraron 83292 carácteres únicos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLKL9BJKWMdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d866c8-9cf1-4d02-b0cc-2728fff88394"
      },
      "source": [
        "# LUT para convertir de caracter a entero\n",
        "char2idx = {i:u for u, i in enumerate(vocab)}\n",
        "\n",
        "# mostramos la codificación de los primeros 20 carácteres\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print(f'  {repr(char):4s}: {char2idx[char]:3d}')\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  'BBHD':   0\n",
            "  'EASYSOL':   1\n",
            "  'BODD':   2\n",
            "  'BanEstadoChile':   3\n",
            "  'BanReservas':   4\n",
            "  'BPOD':   5\n",
            "  'BCOPICHI':   6\n",
            "  'BANG':   7\n",
            "  'BBGN':   8\n",
            "  'BGRECU':   9\n",
            "  'BPACIF':  10\n",
            "  'BCOOME':  11\n",
            "  'COPFAV':  12\n",
            "  'PICHINCHA-COL':  13\n",
            "  'PRDUBANK':  14\n",
            "  'BAFIRM':  15\n",
            "  'BINTCH':  16\n",
            "  'BANGAB':  17\n",
            "  'FALACL':  18\n",
            "  'FALAPE':  19\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUpa4KawQ0N3"
      },
      "source": [
        "newlist = list()\n",
        "for i in vocab.keys():\n",
        "    newlist.append(i)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmVz3jVTXMoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00979613-a6e7-450d-9df8-aefe075082b9"
      },
      "source": [
        "# LUT para convertir de entero a string\n",
        "idx2char = np.array(newlist)\n",
        "len(idx2char)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcEWlq80XQjv"
      },
      "source": [
        "# convertimos todo el texto a enteros:\n",
        "text_as_int=[]\n",
        "for c in texto:\n",
        "  try:\n",
        "    text_as_int.append(vocab[c])\n",
        "  except Exception as e:\n",
        "    pass"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "komeyL4_NNfl"
      },
      "source": [
        "text_as_int=np.array(text_as_int)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfBLfAeRYB3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097bb891-b7ee-471d-dbd0-e16b7c29ccad"
      },
      "source": [
        "print(f\"Carácteres originales:\\n\\t{repr(texto[10:30])}\")\n",
        "print(f\"Codificación:\\n\\t{text_as_int[10:30]}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carácteres originales:\n",
            "\t['REGISTRARTDTP:GoDaddy.com,LLC', 'HOSTINGDTP:HGBLOCK-4', 'PAISDTP:UK', 'PATHDTP:wp-content/bhd/bhd2/', 'BBHD', '199.188.200.225', 'REGISTRANTDTP:nan', 'REGISTRARTDTP:nan', 'HOSTINGDTP:NCNET-1', 'PAISDTP:nan', 'PATHDTP:nan', 'BBHD', '35.173.211.168', 'REGISTRANTDTP:LegalDepartment', 'REGISTRARTDTP:MarkMonitor,Inc.', 'HOSTINGDTP:AT-88-Z', 'PAISDTP:US', 'PATHDTP:login/index.php', 'BBHD', '198.54.125.95']\n",
            "Codificación:\n",
            "\t[80357 80918 83016 31822     0   240 68578 80358 80919 83017 31823     0\n",
            "   241 68579 80359 80920 83018 31824     0   242]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdIdxSYoZU6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d85452-e9f3-4f2e-8530-4261da80697d"
      },
      "source": [
        "# definimos la longitud de cada secuencia\n",
        "seq_length = 6\n",
        "# definimos el número de ejemplos que verá la red en cada época\n",
        "examples_per_epoch = len(texto) // (seq_length + 1)\n",
        "# creamos un dataset con la representación vectorizada\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "# mostramos un ejemplo con un batch de tamaño 10\n",
        "for i in char_dataset.take(7):\n",
        "    print(idx2char[i])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BBHD\n",
            "63.250.38.253\n",
            "REGISTRANTDTP:WhoisGuardProtected\n",
            "REGISTRARTDTP:NAMECHEAPINC\n",
            "HOSTINGDTP:NAMEC-4\n",
            "PAISDTP:PA\n",
            "PATHDTP:https/_/_/bhdleon.com.do/azul/wps/portal/BHD/Inicio/!ut/p/z1/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQN-sIlraF6N"
      },
      "source": [
        "Utilizamos el método ```batch``` para convertir las secuencias al tamaño que deseamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHTN-8BuaJyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766a94ab-c847-42b1-d268-059cc65bdbf0"
      },
      "source": [
        "# obtenemos las secuencias de tamaño 100 + 1\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "# mostramos las primeras 5 secuencias\n",
        "for item in sequences.take(10):\n",
        "    print(repr(' '.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'BBHD 63.250.38.253 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA PATHDTP:https/_/_/bhdleon.com.do/azul/wps/portal/BHD/Inicio/!ut/p/z1/'\n",
            "'BBHD 108.167.140.148 REGISTRANTDTP:nan REGISTRARTDTP:GoDaddy.com,LLC HOSTINGDTP:HGBLOCK-4 PAISDTP:UK PATHDTP:wp-content/bhd/bhd2/'\n",
            "'BBHD 199.188.200.225 REGISTRANTDTP:nan REGISTRARTDTP:nan HOSTINGDTP:NCNET-1 PAISDTP:nan PATHDTP:nan'\n",
            "'BBHD 35.173.211.168 REGISTRANTDTP:LegalDepartment REGISTRARTDTP:MarkMonitor,Inc. HOSTINGDTP:AT-88-Z PAISDTP:US PATHDTP:login/index.php'\n",
            "'BBHD 198.54.125.95 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA PATHDTP:DO/COVID-19/wps/portal/BHD/Inicio/!ut/p/z1/'\n",
            "'BBHD 5.101.152.163 REGISTRANTDTP:nan REGISTRARTDTP:nan HOSTINGDTP:RIPE-5 PAISDTP:nan PATHDTP:BHD/bhd/wps/portal/BHD/Inicio/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziTSxdDDxNTAy93T3/dz/d5/L2dBISEvZ0FBIS9nQSEh/'\n",
            "'BBHD 51.83.110.181 REGISTRANTDTP:nan REGISTRARTDTP:nan HOSTINGDTP:RIPE-ERX-51 PAISDTP:nan PATHDTP:BHD/bhd/wps/portal/BHD/Inicio/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziTSxdDDxNTAy93T3/dz/d5/L2dBISEvZ0FBIS9nQSEh/'\n",
            "'BBHD 213.186.33.4 REGISTRANTDTP:nan REGISTRARTDTP:nan HOSTINGDTP:RIPE-213 PAISDTP:nan PATHDTP:modules/vtemskitter/img/ytre/'\n",
            "'BBHD 148.66.138.126 REGISTRANTDTP:RegistrationPrivate REGISTRARTDTP:GoDaddy.com,LLC HOSTINGDTP:APNIC PAISDTP:US PATHDTP:nan'\n",
            "'BBHD 162.0.232.236 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA PATHDTP:sauolitol58545654654/papirufo/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1hNpLiAbJqR"
      },
      "source": [
        "# creamos una función para separar el último caracter\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "# aplicamos la función a todo el dataset original\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlGCzS_ubhug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d2e6a8-0d29-4880-e434-4f11f3020399"
      },
      "source": [
        "for entrada, salida in dataset.take(10):\n",
        "    print(\"Entrada:\")\n",
        "    print(repr(''.join(idx2char[entrada.numpy()])))\n",
        "    print(\"Salida:\")\n",
        "    print(repr(''.join(idx2char[salida.numpy()])))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada:\n",
            "'BBHD63.250.38.253REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PA'\n",
            "Salida:\n",
            "'63.250.38.253REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PAPATHDTP:https/_/_/bhdleon.com.do/azul/wps/portal/BHD/Inicio/!ut/p/z1/'\n",
            "Entrada:\n",
            "'BBHD108.167.140.148REGISTRANTDTP:nanREGISTRARTDTP:GoDaddy.com,LLCHOSTINGDTP:HGBLOCK-4PAISDTP:UK'\n",
            "Salida:\n",
            "'108.167.140.148REGISTRANTDTP:nanREGISTRARTDTP:GoDaddy.com,LLCHOSTINGDTP:HGBLOCK-4PAISDTP:UKPATHDTP:wp-content/bhd/bhd2/'\n",
            "Entrada:\n",
            "'BBHD199.188.200.225REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:NCNET-1PAISDTP:nan'\n",
            "Salida:\n",
            "'199.188.200.225REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:NCNET-1PAISDTP:nanPATHDTP:nan'\n",
            "Entrada:\n",
            "'BBHD35.173.211.168REGISTRANTDTP:LegalDepartmentREGISTRARTDTP:MarkMonitor,Inc.HOSTINGDTP:AT-88-ZPAISDTP:US'\n",
            "Salida:\n",
            "'35.173.211.168REGISTRANTDTP:LegalDepartmentREGISTRARTDTP:MarkMonitor,Inc.HOSTINGDTP:AT-88-ZPAISDTP:USPATHDTP:login/index.php'\n",
            "Entrada:\n",
            "'BBHD198.54.125.95REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PA'\n",
            "Salida:\n",
            "'198.54.125.95REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PAPATHDTP:DO/COVID-19/wps/portal/BHD/Inicio/!ut/p/z1/'\n",
            "Entrada:\n",
            "'BBHD5.101.152.163REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-5PAISDTP:nan'\n",
            "Salida:\n",
            "'5.101.152.163REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-5PAISDTP:nanPATHDTP:BHD/bhd/wps/portal/BHD/Inicio/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziTSxdDDxNTAy93T3/dz/d5/L2dBISEvZ0FBIS9nQSEh/'\n",
            "Entrada:\n",
            "'BBHD51.83.110.181REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-ERX-51PAISDTP:nan'\n",
            "Salida:\n",
            "'51.83.110.181REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-ERX-51PAISDTP:nanPATHDTP:BHD/bhd/wps/portal/BHD/Inicio/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziTSxdDDxNTAy93T3/dz/d5/L2dBISEvZ0FBIS9nQSEh/'\n",
            "Entrada:\n",
            "'BBHD213.186.33.4REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-213PAISDTP:nan'\n",
            "Salida:\n",
            "'213.186.33.4REGISTRANTDTP:nanREGISTRARTDTP:nanHOSTINGDTP:RIPE-213PAISDTP:nanPATHDTP:modules/vtemskitter/img/ytre/'\n",
            "Entrada:\n",
            "'BBHD148.66.138.126REGISTRANTDTP:RegistrationPrivateREGISTRARTDTP:GoDaddy.com,LLCHOSTINGDTP:APNICPAISDTP:US'\n",
            "Salida:\n",
            "'148.66.138.126REGISTRANTDTP:RegistrationPrivateREGISTRARTDTP:GoDaddy.com,LLCHOSTINGDTP:APNICPAISDTP:USPATHDTP:nan'\n",
            "Entrada:\n",
            "'BBHD162.0.232.236REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PA'\n",
            "Salida:\n",
            "'162.0.232.236REGISTRANTDTP:WhoisGuardProtectedREGISTRARTDTP:NAMECHEAPINCHOSTINGDTP:NAMEC-4PAISDTP:PAPATHDTP:sauolitol58545654654/papirufo/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH-Mr6KuWhmQ"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zym_aOdkFR"
      },
      "source": [
        "Ahora, especificamos el número de batches que usaremos para entrenar la red y un tamaño de buffer, el cual es neceario para aleatorizar localmente las observaciones (```tf.data``` carga este número de muestras en memoria para poder aleatorizar el entrenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW8lgshyeMyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d94d93a-7c22-473c-bde4-40d8de81b8e3"
      },
      "source": [
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "\n",
        "# creamos el dataset con el batch size y el buffer\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 6), (64, 6)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT0XDYsEO_jS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843cd03f-89b5-4285-e346-8f783863f705"
      },
      "source": [
        "dataset.take(10)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64, 6), (64, 6)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuMSQzWN3XbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92efdd0c-4744-4898-8b7a-fe85f0e2df93"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 6), (64, 6)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcBt7C2odr4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecfc23e9-583d-4165-8625-2c55851e7314"
      },
      "source": [
        "idx2char[77760]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'REGISTRANTDTP:saikema'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks1REggkepPH"
      },
      "source": [
        "## 4. SimpleRNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phXkkj7BiRoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "781d2bbb-f221-4885-bcd8-202179eb5726"
      },
      "source": [
        "# dimensión del embedding\n",
        "embedding_dim = 256\n",
        "# número de únidades en la capa recurrente\n",
        "rnn_units = 1024\n",
        "\n",
        "model_srnn = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                            batch_input_shape=[batch_size, None]),\n",
        "                                  tf.keras.layers.SimpleRNN(rnn_units,\n",
        "                                                            return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                            stateful=True,\n",
        "                                                            recurrent_initializer='glorot_uniform'),\n",
        "                                  tf.keras.layers.Dense(vocab_size)])\n",
        "model_srnn.summary()\n",
        "tf.keras.utils.plot_model(model_srnn)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           21322752  \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 83292)         85374300  \n",
            "=================================================================\n",
            "Total params: 108,008,796\n",
            "Trainable params: 108,008,796\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBtt6FTYvSmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a798b5f-651d-42bd-adb5-11d738b78d17"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model_srnn(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "example_pred_seq = example_batch_predictions[0]\n",
        "print(f\"Tamaño de la secuencia de entrada {input_example_batch[0].shape}\")\n",
        "print(f\"Tamaño de la secuencia de salida predicha {example_pred_seq.shape}\")\n",
        "print(f\"Tamaño de la secuencia de salida target {target_example_batch[0].shape}\")\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de la secuencia de entrada (6,)\n",
            "Tamaño de la secuencia de salida predicha (6, 83292)\n",
            "Tamaño de la secuencia de salida target (6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mq_t1EhyqD_"
      },
      "source": [
        "Podemos ver que la predicción para una secuencia de tamaño 100 (códificación en enteros) es una secuencia de tamaño 100 (one-hot). Veamos la distribución del carácter sucesor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbaLorSgkYb1"
      },
      "source": [
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "#\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_toc6WlgjgM"
      },
      "source": [
        "### Entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJUL95SCu2oZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e10635-d0b1-48d0-97f0-e2993bfa09e9"
      },
      "source": [
        "examples_per_epoch"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-kU8K-fggnb"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-gpl3u5mhDn"
      },
      "source": [
        "model_srnn.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZelkdlHen7Sq"
      },
      "source": [
        "# Utilice el siguiente código si desea entrenar el modelo (puede tomar tiempo)\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"srnn.h5\",\n",
        "    save_weights_only=True)\n",
        "#model_srnn.fit(dataset.repeat(), epochs=20, callbacks=[checkpoint_callback],\n",
        "#               steps_per_epoch=(examples_per_epoch//batch_size))\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-De-xFo2TMh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "2c25f06c-2312-4af8-8160-dee2b20ecd89"
      },
      "source": [
        "#\n",
        "# cargamos los pesos del modelo\n",
        "model_srnn.load_weights(\"srnn.h5\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5068d0a6216a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# cargamos los pesos del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_srnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"srnn.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'srnn.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLAaJY0YW9bP"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "#example_batch_predictions = model_srnn(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "#example_pred_seq = example_batch_predictions[0]\n",
        "\n",
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "#print(f\"Carácter sucesor más probable: {idx2char[np.argmax(example_pred_seq[-1])]}\")\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\"#)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3v187e24YT_"
      },
      "source": [
        "## Long short-term memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_y_qrUXJruu"
      },
      "source": [
        "# dimensión del embedding\n",
        "embedding_dim = 256\n",
        "# número de únidades en la capa recurrente\n",
        "rnn_units = 1024\n",
        "\n",
        "model_lstm = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                            batch_input_shape=[batch_size, None]),\n",
        "                                  tf.keras.layers.LSTM(rnn_units,\n",
        "                                                       return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                       stateful=True,\n",
        "                                                       recurrent_initializer='glorot_uniform'),\n",
        "                                  tf.keras.layers.Dense(vocab_size)])\n",
        "model_lstm.summary()\n",
        "tf.keras.utils.plot_model(model_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVLNds8YYpc2"
      },
      "source": [
        "Veamos las distribuciones predichas por el modelo (pesos aleatorios):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCUjEdI6YqLv"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model_lstm(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "example_pred_seq = example_batch_predictions[0]\n",
        "print(f\"Tamaño de la secuencia de entrada {input_example_batch[0].shape}\")\n",
        "print(f\"Tamaño de la secuencia de salida {example_pred_seq.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ1fASX_Y3fz"
      },
      "source": [
        "Veamos la distribución del carácter sucesor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeCuLjCNY4WD"
      },
      "source": [
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))#\n",
        "#\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfa47bZWgphd"
      },
      "source": [
        "###  Entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_OxI8hGK4nL"
      },
      "source": [
        "model_lstm.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPNbfZH2LEYx"
      },
      "source": [
        "\n",
        "#checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "#    filepath=\"lstm.h5\",\n",
        "#    save_weights_only=True)\n",
        "#model_lstm.fit(dataset.repeat(), epochs=20, callbacks=[checkpoint_callback],\n",
        "#               steps_per_epoch=examples_per_epoch//batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAC6VnsPZPIK"
      },
      "source": [
        "# cargamos los pesos del modelo\n",
        "model_lstm.load_weights(\"lstm.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iNqpHUtZqB4"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "#example_batch_predictions = model_lstm(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "#example_pred_seq = example_batch_predictions[0]\n",
        "\n",
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "#print(f\"Carácter sucesor más probable: {idx2char[np.argmax(example_pred_seq[-1])]}\")\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3jaJ58mmA-D"
      },
      "source": [
        "###GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAVFdhd9ktII"
      },
      "source": [
        "# dimensión del embedding\n",
        "embedding_dim = 256\n",
        "# número de únidades en la capa recurrente\n",
        "rnn_units = 1024\n",
        "\n",
        "model_gru = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                           batch_input_shape=[batch_size, None]),\n",
        "                                 tf.keras.layers.GRU(rnn_units,\n",
        "                                                     return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                     stateful=True,\n",
        "                                                     recurrent_initializer='glorot_uniform'),\n",
        "                                 tf.keras.layers.Dense(vocab_size)])\n",
        "model_gru.summary()\n",
        "tf.keras.utils.plot_model(model_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMs4-WdXaIfw"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model_gru(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "example_pred_seq = example_batch_predictions[0]\n",
        "print(f\"Tamaño de la secuencia de entrada {input_example_batch[0].shape}\")\n",
        "print(f\"Tamaño de la secuencia de salida {example_pred_seq.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awJ5Ts-5aV4c"
      },
      "source": [
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQdTKgApgxnj"
      },
      "source": [
        "### Entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ7unzxzlJIQ"
      },
      "source": [
        "model_gru.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrm1I03vuHl9"
      },
      "source": [
        "\n",
        "#checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "#    filepath=\"gru.h5\",\n",
        "#    save_weights_only=True)\n",
        "#model_gru.fit(dataset.repeat(), epochs=20, callbacks=[checkpoint_callback],\n",
        "#              steps_per_epoch=examples_per_epoch//batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFvwekfcaqF8"
      },
      "source": [
        "    # cargamos los pesos del modelo\n",
        "model_gru.load_weights(\"gru.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIrrOkhUa6ow"
      },
      "source": [
        "# obtenemos la predicción para el primer batch\n",
        "#example_batch_predictions = model_gru(input_example_batch)\n",
        "# seleccionamos la secuencia deseada\n",
        "#example_pred_seq = example_batch_predictions[0]\n",
        "\n",
        "#print(\"Entrada: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "#print(f\"Carácter sucesor más probable: {idx2char[np.argmax(example_pred_seq[-1])]}\")\n",
        "#plt.figure(figsize=(20,10))\n",
        "#plt.subplot(211)\n",
        "#plt.bar([repr(i) for i in idx2char], example_pred_seq[-1])\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Logits\")\n",
        "#plt.subplot(212)\n",
        "#plt.bar([repr(i) for i in idx2char], tf.nn.softmax(example_pred_seq[-1]))\n",
        "#plt.xlim([0, 88])\n",
        "#plt.title(\"Probits\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuOs6un9bxQf"
      },
      "source": [
        "# Función que calcula la probabilidad de un Texto de acuerdo a la fórmula dada anteriormente:\n",
        "def log_likelihood(model, text):\n",
        "    res = []\n",
        "    for i,char in enumerate(\" \".split(text)[:-1]):\n",
        "        # creamos un batch de ceros de secuencias de tamaño 1\n",
        "        text_int = np.zeros((64,1))\n",
        "        # asignamos la codificación del caracter\n",
        "        text_int[0] = char2idx[char]\n",
        "        # obtenemos la distribución del carácter sucesor\n",
        "        probs = tf.nn.softmax(model.predict(text_int, batch_size=64)[0,-1])\n",
        "        # calculamos el log-likelihood del siguiente caracter\n",
        "        res.append(probs[char2idx[text[i+1]]].numpy())\n",
        "    return np.log(res).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVWFne_7uYBY"
      },
      "source": [
        "log_likelihood(model_srnn,\"BBHD 198.54.125.95 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXxhaO_zu7W"
      },
      "source": [
        "Ahora, veamos el texto generado con cada uno de los modelos entrenados:\n",
        "\n",
        "* **SimpleRNN**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtB23Xd56ic"
      },
      "source": [
        "Comenzamos generando texto con un valor de temperatura bajo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfZw49Mmv8Dp"
      },
      "source": [
        "def generate_text(model, start_string, text_len=np.random.randint(10), temperature=0.3):\n",
        "    \n",
        "    # vectorizamos el string inicial\n",
        "    start_string=start_string.split(' ')\n",
        "    #start_string=start_string[0]+start_string[1].replace('',' ')\n",
        "    #print(start_string)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Lista para guardar los resultados\n",
        "    text_generated = []\n",
        "\n",
        "    # Reiniciamos los estados del modelo\n",
        "    model.reset_states()\n",
        "    # iteramos para obtener el número de carácteres deseado\n",
        "    for i in range(text_len):\n",
        "        # obtenemos las predicciones\n",
        "        predictions = model(input_eval)\n",
        "        # removemos el eje de los batch\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        print(predictions[:])\n",
        "        # utilizamos la distribución categorica para obtener el siguiente caracter\n",
        "        #predictions = predictions / temperature\n",
        "        \n",
        "        predicted_id = tf.sigmoid.categorical()\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        #print(predicted_id)\n",
        "        # predicted_id es el caracter predicho (este será la entrada en la siguiente iteración)\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        # agregamos el string correspondiente al id predicho\n",
        "        if idx2char[predicted_id]!=[]:\n",
        "          text_generated.append(idx2char[predicted_id])\n",
        "        else:\n",
        "          if i!=0:\n",
        "            i=i-1\n",
        "    \n",
        "        #predicted_id = tf.argmax(tf.nn.softmax(predictions), 1)[-1,0].numpy()\n",
        "        \n",
        "    return (text_generated[0])#start_string.split(' ')[0]+' http://'+''.join(start_string.split(' ')[1:]) +'/'+'/'.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLHN4g1Rttly"
      },
      "source": [
        "print(generate_text(model_srnn, start_string=u\"BBHD 198.54.125.95 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA\", temperature=0.3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UyN_S4r7C_B"
      },
      "source": [
        "Ahora, veamos el resultado con un valor de temperatura alto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnkzB4Q37jS7"
      },
      "source": [
        "print(generate_text(model_srnn, start_string=u\"ADP adp.com : \", temperature=2.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DZolo2B8WRU"
      },
      "source": [
        "Lo ideal es encontrar un valor de temperatura apropiado, es decir, donde el texto generado no sea tan repetitivo o determinístico ni tan aleatorio e incoherente, veamos un ejemplo con un valor apropiado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWO4Jfwg94n3"
      },
      "source": [
        "print(generate_text(model_srnn, start_string=u\"Dios dijo: \", temperature=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yufP-FIO0Jpd"
      },
      "source": [
        "* **LSTM**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdb6Vv3h0MB2"
      },
      "source": [
        "# creamos un modelo con un tamaño de batche 1 con los pesos del modelo entrenado\n",
        "model_lstm = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                            batch_input_shape=[1, None]),\n",
        "                                  tf.keras.layers.LSTM(rnn_units,\n",
        "                                                       return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                       stateful=True,\n",
        "                                                       recurrent_initializer='glorot_uniform'),\n",
        "                                  tf.keras.layers.Dense(vocab_size)])\n",
        "\n",
        "model_lstm.load_weights(\"lstm.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJGEZwu0dLa"
      },
      "source": [
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwlj3j660e3C"
      },
      "source": [
        "print(generate_text(model_lstm, start_string=u\"BBHD 63.250.38.253 REGISTRANTDTP:WhoisGuardProtected REGISTRARTDTP:NAMECHEAPINC HOSTINGDTP:NAMEC-4 PAISDTP:PA\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF2Bx_l03ran"
      },
      "source": [
        "model_lstm.predict([3, 143, 123, 212])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxHW4U6t0tlO"
      },
      "source": [
        "* **GRU**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywM-7G4L01Gq"
      },
      "source": [
        "# creamos un modelo con un tamaño de batche 1 con los pesos del modelo entrenado\n",
        "model_gru = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                            batch_input_shape=[1, None]),\n",
        "                                 tf.keras.layers.GRU(rnn_units,\n",
        "                                                     return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                     stateful=True,\n",
        "                                                     recurrent_initializer='glorot_uniform'),\n",
        "                                 tf.keras.layers.Dense(vocab_size)])\n",
        "\n",
        "model_gru.load_weights(\"gru.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjn4Lnbj0_LW"
      },
      "source": [
        "model_gru.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Azwc_Lq1CHn"
      },
      "source": [
        "print(generate_text(model_gru, start_string=u\"SMBC smbcghy.com\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk-_p3xuOfxi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}